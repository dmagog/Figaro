# Оптимизация загрузки данных

## Проблема
Исходная реализация загрузки данных была неэффективна для больших файлов (до 50,000 строк):
- N+1 проблема: отдельный запрос к БД для каждой записи
- Множественные коммиты: каждая запись коммитится отдельно
- Отсутствие батчинга

## Решение

### 1. Батчинг операций
- Загрузка данных порциями по 1000 записей (настраивается через `DATA_LOADER_BATCH_SIZE`)
- Группировка операций вставки
- Прогресс-бар для отслеживания загрузки

### 2. Кэширование связей
- Загрузка связанных данных (залы, концерты) в память перед обработкой
- Избежание повторных запросов к БД для поиска связей

### 3. Bulk операции
- Массовая вставка новых записей через `session.add_all()`
- Оптимизированный поиск существующих записей одним запросом

### 4. Отключение внешних ключей
- Временное отключение проверки FK для ускорения загрузки
- Автоматическое включение после завершения

## Использование

### Автоматическая загрузка
```python
from database.database import init_db

# Загружает все данные с оптимизациями
init_db(demostart=True)
```

### Ручная загрузка
```python
from services.crud.data_loader import load_all_data

load_all_data(
    session=session,
    df_halls=halls_df,
    df_concerts=concerts_df,
    df_artists=artists_df,
    df_details=compositions_df,
    df_ops=purchases_df,
    disable_fk_checks=True
)
```

### Настройка размера батча
```bash
export DATA_LOADER_BATCH_SIZE=2000  # Увеличить размер батча
```

## Тестирование производительности

Запустите тест производительности:
```bash
cd app
python test_data_loading.py
```

## Ожидаемые улучшения

Для файла с 50,000 покупками:
- **Было**: ~10-15 минут
- **Стало**: ~2-3 минуты
- **Ускорение**: 5-7x

## Мониторинг

Логирование показывает:
- Прогресс загрузки по батчам
- Время обработки каждого этапа
- Количество обработанных записей
- Предупреждения о пропущенных записях

## Рекомендации

1. **Размер батча**: Начните с 1000, увеличьте до 2000-5000 для больших файлов
2. **Память**: Убедитесь, что у вас достаточно RAM для загрузки всех Excel файлов
3. **База данных**: Используйте PostgreSQL для лучшей производительности
4. **Индексы**: Создайте индексы на внешних ключах после загрузки

## Устранение неполадок

### Ошибка "Out of memory"
- Уменьшите размер батча
- Обрабатывайте файлы по частям

### Медленная загрузка
- Проверьте индексы в БД
- Увеличьте размер батча
- Отключите логирование SQL запросов (`echo=False`)

### Пропущенные записи
- Проверьте логи на предупреждения
- Убедитесь в корректности данных в Excel файлах 
